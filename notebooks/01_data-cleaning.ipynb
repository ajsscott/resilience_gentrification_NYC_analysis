{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccca6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01_data-cleaning.ipynb\n",
    "# Initial Cleaning, Geoprocessing and Joining of Resilience Projects Data\n",
    "\n",
    "# Libraries\n",
    "import pickle   \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from pathlib import Path\n",
    "from shapely.geometry import Point\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path().resolve().parent / \"src\"))\n",
    "from cleaning_functions import preview_df\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path(\"../data/raw/\")\n",
    "TRACTS_PATH = DATA_DIR / \"tl_2020_36_tract/tl_2020_36_tract.shp\"\n",
    "\n",
    "RESILIENCE_POINTS_PATH = (\n",
    "    DATA_DIR / \"resilience_projects/RecoveryResiliencyProjectMap_points_20250217.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2100a544",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- LOAD CENSUS TRACTS ---\n",
    "# Load NYC Census Tracts\n",
    "gdf_tracts = gpd.read_file(TRACTS_PATH)\n",
    "gdf_tracts = gdf_tracts.to_crs(epsg=2263)\n",
    "\n",
    "preview_df(gdf_tracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672fb78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- LOAD RESILIENCE PROJECTS DATA AS POINTS GEOMETRY ---\n",
    "# Load Resilience Points Data\n",
    "points = pd.read_csv(RESILIENCE_POINTS_PATH)\n",
    "\n",
    "# Convert geometry\n",
    "points[\"geometry\"] = points[\"the_geom\"].apply(wkt.loads)\n",
    "gdf_points = gpd.GeoDataFrame(points, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "# Convert to NYC projected CRS\n",
    "gdf_points = gdf_points.to_crs(epsg=2263)\n",
    "\n",
    "# Clean column names\n",
    "gdf_points.columns = gdf_points.columns.str.lower().str.strip()\n",
    "\n",
    "preview_df(gdf_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c314abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- JOIN RESILIENCE PROJECT POINTs TO CENSUS TRACTS ---\n",
    "# Assign each resilience project to a census tract \n",
    "resilience_with_tract = gpd.sjoin(\n",
    "    gdf_points, gdf_tracts[[\"GEOID\", \"geometry\"]], how=\"left\", predicate=\"within\"\n",
    ")\n",
    "\n",
    "# Only completed projects\n",
    "resilience_with_tract = resilience_with_tract.dropna(subset=[\"compdate\"])\n",
    "\n",
    "# Clean and extract project year\n",
    "resilience_with_tract[\"year\"] = (\n",
    "    resilience_with_tract[\"compdate\"]\n",
    "    .str.extract(r\"(\\d{4})\") \n",
    "    .astype(float)\n",
    "    .astype(\"Int32\") \n",
    ")\n",
    "\n",
    "preview_df(resilience_with_tract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347f3cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- SUMMARIZE RESILIENCE PROJECTS OVER TIME BY CENSUS TRACT ---\n",
    "# Create tract-year level summary statistics\n",
    "resilience_summary = (\n",
    "    resilience_with_tract.groupby([\"GEOID\", \"year\"])\n",
    "    .agg(\n",
    "        has_resilience_project=(\"compdate\", lambda x: 1), \n",
    "        proj_count=(\"compdate\", \"count\"),\n",
    "        projval_total=(\"projval\", \"sum\"),\n",
    "        #\n",
    "        **{\n",
    "            f\"onenyc_{cat}\": (\"onenyc\", lambda x, cat=cat: (x == cat).sum())\n",
    "            for cat in resilience_with_tract[\"onenyc\"].unique()\n",
    "        },\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "preview_df(resilience_summary)\n",
    "print(resilience_summary[\"has_resilience_project\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5052577",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- LOAD MERGED AND GEOCODED ACS DATA ---\n",
    "# LOAD ACS\n",
    "with open(DATA_DIR / \"../processed/acs_merged.pkl\", \"rb\") as f:\n",
    "    acs_merged = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fa035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PREP AND CLEAN ACS DATA ---\n",
    "# Create derived share variables\n",
    "acs_merged[\"poverty_rate\"] = acs_merged[\"poverty_below\"] / acs_merged[\"poverty_total\"]\n",
    "acs_merged[\"race_white_share\"] = acs_merged[\"race_white\"] / acs_merged[\"race_total\"]\n",
    "acs_merged[\"race_black_share\"] = acs_merged[\"race_black\"] / acs_merged[\"race_total\"]\n",
    "acs_merged[\"race_asian_share\"] = acs_merged[\"race_asian\"] / acs_merged[\"race_total\"]\n",
    "acs_merged[\"race_mixed_share\"] = acs_merged[\"race_mixed\"] / acs_merged['race_total']\n",
    "acs_merged[\"race_native_pi_other_share\"] = (\n",
    "    acs_merged[\"race_native\"]\n",
    "    + acs_merged[\"race_pi\"]\n",
    "    + acs_merged[\"race_other\"]\n",
    ") / acs_merged[\"race_total\"]\n",
    "\n",
    "acs_merged[\"edu_no_diploma_share\"] = (\n",
    "    acs_merged[\"education_no_diploma\"] / acs_merged[\"population\"]\n",
    ")\n",
    "acs_merged[\"edu_high_school_share\"] = (\n",
    "    acs_merged[\"education_high_school\"] / acs_merged[\"population\"]\n",
    ")\n",
    "acs_merged[\"edu_associates_share\"] = (\n",
    "    acs_merged[\"education_associates\"] / acs_merged[\"population\"]\n",
    ")\n",
    "acs_merged[\"edu_bachelors_share\"] = (\n",
    "    acs_merged[\"education_bachelors\"] / acs_merged[\"population\"]\n",
    ")\n",
    "acs_merged[\"edu_masters_share\"] = (\n",
    "    acs_merged[\"education_masters\"] / acs_merged[\"population\"]\n",
    ")\n",
    "acs_merged[\"edu_professional_share\"] = (\n",
    "    acs_merged[\"education_professional\"] / acs_merged[\"population\"]\n",
    ")\n",
    "acs_merged[\"edu_doctorate_share\"] = (\n",
    "    acs_merged[\"education_doctorate\"] / acs_merged[\"population\"]\n",
    ")\n",
    "acs_merged[\"edu_college_plus\"] = (\n",
    "    acs_merged[\"education_bachelors\"]\n",
    "    + acs_merged[\"education_masters\"]\n",
    "    + acs_merged[\"education_professional\"]\n",
    "    + acs_merged[\"education_doctorate\"]\n",
    ")\n",
    "acs_merged[\"edu_college_plus_share\"] = (\n",
    "    acs_merged[\"edu_college_plus\"] / acs_merged[\"population\"]\n",
    ")\n",
    "\n",
    "# Build tract-year base from ACS \n",
    "tract_years = acs_merged[[\"GEOID\", \"year\"]].drop_duplicates().dropna()\n",
    "tract_years[\"year\"] = tract_years[\"year\"].astype(int)\n",
    "\n",
    "# Merge in full ACS demographic panel\n",
    "tract_base = tract_years.merge(acs_merged, on=[\"GEOID\", \"year\"], how=\"left\")\n",
    "\n",
    "# Merge in resilience summary\n",
    "tract_base = tract_base.merge(resilience_summary, on=[\"GEOID\", \"year\"], how=\"left\")\n",
    "\n",
    "# Fill NA values for resilience columns\n",
    "tract_base[\"has_resilience_project\"] = tract_base[\"has_resilience_project\"].fillna(0).astype(int)\n",
    "tract_base[\"proj_count\"] = tract_base[\"proj_count\"].fillna(0).astype(int)\n",
    "tract_base[\"projval_total\"] = tract_base[\"projval_total\"].fillna(0)\n",
    "\n",
    "# Fill NA in dummy columns like onenyc_*\n",
    "onenyc_cols = [col for col in tract_base.columns if col.startswith(\"onenyc_\")]\n",
    "tract_base[onenyc_cols] = tract_base[onenyc_cols].fillna(0).astype(int)\n",
    "\n",
    "# Get First Project Year Per Tract from Point-Level Data \n",
    "first_project_year = (\n",
    "    resilience_with_tract.groupby(\"GEOID\")[\"year\"]\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"year\": \"first_project_year\"})\n",
    ")\n",
    "\n",
    "# Merge into the Tract-Year Panel\n",
    "gdf_tracts_with_resilience = tract_base.merge(\n",
    "    first_project_year, on=\"GEOID\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Create Post-Project Indicator\n",
    "gdf_tracts_with_resilience[\"post_project\"] = (\n",
    "    (gdf_tracts_with_resilience[\"year\"] >= gdf_tracts_with_resilience[\"first_project_year\"]).fillna(False).astype(int)\n",
    ")\n",
    "# Years Since Project (set to 0 if not yet implemented) \n",
    "gdf_tracts_with_resilience[\"years_since_project\"] = (\n",
    "    gdf_tracts_with_resilience[\"year\"]\n",
    "    - gdf_tracts_with_resilience[\"first_project_year\"]\n",
    ")\n",
    "\n",
    "gdf_tracts_with_resilience[\"years_since_project\"] = gdf_tracts_with_resilience[\n",
    "    \"years_since_project\"\n",
    "].where(gdf_tracts_with_resilience[\"first_project_year\"].notna())\n",
    "\n",
    "gdf_tracts_with_resilience.loc[gdf_tracts_with_resilience[\"years_since_project\"] < 0, \"years_since_project\"] = np.nan\n",
    "\n",
    "# Cumulative Exposure Duration (integer)\n",
    "gdf_tracts_with_resilience[\"project_exposure_duration\"] = (\n",
    "    gdf_tracts_with_resilience[\"years_since_project\"].fillna(0).astype(int)\n",
    ")\n",
    "\n",
    "# Lagged Exposure Dummies (1 through 5 years post-project)\n",
    "for lag in range(1, 6):\n",
    "    gdf_tracts_with_resilience[f\"post_project_lag{lag}\"] = (\n",
    "        (gdf_tracts_with_resilience[\"years_since_project\"] == lag)\n",
    "        .fillna(False)\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "# Ensure the GeoDataFrame uses the 'geometry' column for geometry and set CRS to EPSG:2263\n",
    "gdf_tracts_with_resilience = gpd.GeoDataFrame(\n",
    "    gdf_tracts_with_resilience,\n",
    "    geometry=\"geometry\",\n",
    "    crs=\"EPSG:2263\"\n",
    ")\n",
    "\n",
    "preview_df(gdf_tracts_with_resilience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c9dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- LOAD EVICTIONS DATA ---\n",
    "# Load Evictions Data\n",
    "evictions = pd.read_csv(DATA_DIR / \"evictions/Evictions_20250219.csv\", dtype=str)\n",
    "\n",
    "# Clean column names\n",
    "evictions.columns = evictions.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('/', '_')\n",
    "\n",
    "# Clean column types\n",
    "evictions['executed_date'] = pd.to_datetime(evictions['executed_date'], format='%m/%d/%Y', errors='coerce')\n",
    "evictions['latitude'] = pd.to_numeric(evictions['latitude'], errors='coerce')\n",
    "evictions['longitude'] = pd.to_numeric(evictions['longitude'], errors='coerce')\n",
    "evictions['year'] = evictions['executed_date'].dt.year\n",
    "\n",
    "# Drop rows with missing coordinates or dates\n",
    "evictions_clean = evictions.dropna(subset=['latitude', 'longitude', 'executed_date'])\n",
    "\n",
    "\n",
    "# Create geometry column from lat/lon (if not already a GeoDataFrame)\n",
    "gdf_evictions = gpd.GeoDataFrame(\n",
    "    evictions_clean.copy(),\n",
    "    geometry=gpd.points_from_xy(\n",
    "        evictions_clean[\"longitude\"], evictions_clean[\"latitude\"]\n",
    "    ),\n",
    "    crs=\"EPSG:4326\",\n",
    ")\n",
    "\n",
    "# Project to match the tracts CRS\n",
    "gdf_evictions = gdf_evictions.to_crs(gdf_tracts.crs)\n",
    "\n",
    "# Spatial join to assign GEOID from tracts\n",
    "gdf_evictions = gpd.sjoin(\n",
    "    gdf_evictions, gdf_tracts[[\"GEOID\", \"geometry\"]], how=\"left\", predicate=\"within\"\n",
    ")\n",
    "\n",
    "# Group by GEOID and year to count evictions per tract-year\n",
    "evictions_by_tract_year = (\n",
    "    gdf_evictions.groupby([\"GEOID\", \"year\"]).size().reset_index(name=\"evictions_count\")\n",
    ")\n",
    "\n",
    "# Merge evictions into resilience panel by GEOID and year\n",
    "gdf_tracts_with_resilience = gdf_tracts_with_resilience.merge(\n",
    "    evictions_by_tract_year, on=[\"GEOID\", \"year\"], how=\"left\"\n",
    ")\n",
    "\n",
    "# Fill tracts with no recorded evictions with 0\n",
    "gdf_tracts_with_resilience[\"evictions_count\"] = (\n",
    "    gdf_tracts_with_resilience[\"evictions_count\"].fillna(0).astype(int)\n",
    ")\n",
    "\n",
    "# Separate by Residential vs Commercial Evictions \n",
    "eviction_type_summary = (\n",
    "    gdf_evictions.groupby([\"GEOID\", \"year\", \"residential_commercial\"])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    .reset_index()\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"Residential\": \"eviction_residential\",\n",
    "            \"Commercial\": \"eviction_commercial\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# Merge type-specific counts\n",
    "gdf_tracts_with_resilience = gdf_tracts_with_resilience.merge(\n",
    "    eviction_type_summary, on=[\"GEOID\", \"year\"], how=\"left\"\n",
    ")\n",
    "\n",
    "# Fill missing type counts with 0\n",
    "for col in [\"eviction_residential\", \"eviction_commercial\"]:\n",
    "    if col in gdf_tracts_with_resilience.columns:\n",
    "        gdf_tracts_with_resilience[col] = (\n",
    "            gdf_tracts_with_resilience[col].fillna(0).astype(int)\n",
    "        )\n",
    "    else:\n",
    "        gdf_tracts_with_resilience[col] = (\n",
    "            0  # if column missing (e.g., only residential data)\n",
    "        )\n",
    "\n",
    "# Calculate eviction rate (residential per 1,000 residents)\n",
    "gdf_tracts_with_resilience[\"eviction_rate_per_1000\"] = (\n",
    "    gdf_tracts_with_resilience[\"eviction_residential\"]\n",
    "    * 1000\n",
    "    / gdf_tracts_with_resilience[\"population\"]\n",
    ")\n",
    "\n",
    "# Handle infinite or undefined rates\n",
    "gdf_tracts_with_resilience[\"eviction_rate_per_1000\"] = gdf_tracts_with_resilience[\n",
    "    \"eviction_rate_per_1000\"\n",
    "].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Flag High Eviction Years: above 90th percentile by tract \n",
    "def flag_high_evictions(group):\n",
    "    threshold = group[\"eviction_residential\"].quantile(0.90)\n",
    "    group[\"high_eviction_year\"] = (group[\"eviction_residential\"] >= threshold).astype(\n",
    "        int\n",
    "    )\n",
    "    return group\n",
    "\n",
    "gdf_merged = gdf_tracts_with_resilience.groupby(\n",
    "    \"GEOID\", group_keys=False\n",
    ").apply(flag_high_evictions)\n",
    "\n",
    "gdf_merged = gpd.GeoDataFrame(gdf_merged, geometry=\"geometry\", crs=\"EPSG:2263\")\n",
    "\n",
    "# Handle Invalid Geometries (if any)\n",
    "gdf_merged = gdf_merged[gdf_merged.is_valid]  \n",
    "\n",
    "gdf_merged[\"GEOID\"] = gdf_merged[\"GEOID\"].astype(int)\n",
    "gdf_merged[\"year\"] = gdf_merged[\"year\"].astype(int)\n",
    "\n",
    "# Fill first_project_year with 0 to indicate \"never treated\"\n",
    "gdf_merged[\"first_project_year\"] = (\n",
    "    gdf_merged[\"first_project_year\"].fillna(0).astype(int)\n",
    ")\n",
    "\n",
    "# Fill years_since_project with -1 to indicate \"not treated yet\"\n",
    "gdf_merged[\"years_since_project\"] = (\n",
    "    gdf_merged[\"years_since_project\"].fillna(-1).astype(int)\n",
    ")\n",
    "\n",
    "# Extract latitude and longitude from geometry\n",
    "gdf_merged[\"latitude\"] = gdf_merged.geometry.centroid.y\n",
    "gdf_merged[\"longitude\"] = gdf_merged.geometry.centroid.x\n",
    "\n",
    "preview_df(gdf_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a27cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EXPORT DATA ---\n",
    "\n",
    "# As Pickle\n",
    "gdf_merged.to_pickle(DATA_DIR / \"../modeling/gdf_tracts.pkl\")\n",
    "\n",
    "# As CSV\n",
    "gdf_for_csv = gdf_merged.drop(columns=[\"geometry\"])\n",
    "gdf_merged.to_csv(\n",
    "    DATA_DIR / \"../modeling/tracts.csv\", index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ggent-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
