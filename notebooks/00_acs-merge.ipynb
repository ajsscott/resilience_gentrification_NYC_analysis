{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d99ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 00_acs-merge.ipynb\n",
    "# Initial Cleaning and Standardization of ACS data from 2013 to 2013 for various tables\n",
    "\n",
    "# Libraries\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path().resolve().parent / \"src\"))\n",
    "from cleaning_functions import preview_df\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path(\"../data/\")\n",
    "ACS_DIR = DATA_DIR / \"acs\"\n",
    "TRACTS_PATH = DATA_DIR / \"tl_2020_36_tract/tl_2020_36_tract.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd64b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- FUNCTION TO LOAD DATA ---\n",
    "\n",
    "# Load ACS Data\n",
    "def load_clean_acs(folder, col_map, topic):\n",
    "    \"\"\"\n",
    "    Loads and cleans ACS data from a specified folder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder : str or Path\n",
    "        Path to the folder containing ACS CSV files.\n",
    "    col_map : dict\n",
    "        Dictionary mapping original ACS column names to new column names.\n",
    "    topic : str\n",
    "        Topic of the ACS data (e.g., 'demographics', 'housing').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Concatenated and cleaned DataFrame with selected and renamed columns, including 'GEOID' and 'year'.\n",
    "    \"\"\"\n",
    "    all_files = sorted(glob.glob(os.path.join(folder, \"*-Data.csv\")))\n",
    "    dfs = []\n",
    "\n",
    "    for file in all_files:\n",
    "        # Extract year from filename (assuming contains '20XX')\n",
    "        filename = os.path.basename(file)\n",
    "        match = re.search(r\"20\\d{2}\", filename)\n",
    "        if match:\n",
    "            year = match.group()\n",
    "        else:\n",
    "            raise ValueError(f\"Year not found in filename: {filename}\")\n",
    "\n",
    "        print(f\"Loading {topic} data for {year} from {file}\")\n",
    "\n",
    "        df = pd.read_csv(file, dtype=str)\n",
    "        df.columns = df.columns.str.strip()\n",
    "\n",
    "        # Add year column\n",
    "        df[\"year\"] = int(year)\n",
    "\n",
    "        df['GEOID'] = df['GEO_ID']\n",
    "\n",
    "        # Select relevant columns and rename\n",
    "        cols_to_keep = [\"GEOID\", \"year\"] + list(col_map.keys())\n",
    "        df_clean = df[cols_to_keep]\n",
    "        df_clean = df_clean.rename(columns=col_map)\n",
    "\n",
    "        for col in col_map.values():\n",
    "            df_clean[col] = pd.to_numeric(df_clean[col], errors=\"coerce\")\n",
    "\n",
    "        dfs.append(df_clean)\n",
    "\n",
    "    return pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4b19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- DEFINE TABLES AND VARIABLES FOR INPUT ---\n",
    "# Define mappings per table\n",
    "rent_cols = {\"B25077_001E\": \"median_rent\"}\n",
    "pop_cols = {\"B01003_001E\": \"population\"}\n",
    "poverty_cols = {\"B17017_001E\": \"poverty_total\", \"B17017_002E\": \"poverty_below\"}\n",
    "race_cols = {\n",
    "    \"B02001_001E\": \"race_total\",\n",
    "    \"B02001_002E\": \"race_white\",\n",
    "    \"B02001_003E\": \"race_black\",\n",
    "    \"B02001_004E\": \"race_native\",\n",
    "    \"B02001_005E\": \"race_asian\",\n",
    "    \"B02001_006E\": \"race_pi\",\n",
    "    \"B02001_007E\": \"race_other\",\n",
    "    \"B02001_008E\": \"race_mixed\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606bf02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- LOAD AND PREVIEW DATA ---\n",
    "# ---- Load latest available data ----\n",
    "rent = load_clean_acs(\n",
    "    folder=os.path.join(ACS_DIR, \"ACS_median-rent\"),\n",
    "    col_map=rent_cols,\n",
    "    topic=\"median_rent\",\n",
    ")\n",
    "pop = load_clean_acs(\n",
    "    folder=os.path.join(ACS_DIR, \"ACS_population\"), col_map=pop_cols, topic=\"population\"\n",
    ")\n",
    "poverty = load_clean_acs(\n",
    "    folder=os.path.join(ACS_DIR, \"ACS_poverty\"), col_map=poverty_cols, topic=\"poverty\"\n",
    ")\n",
    "race = load_clean_acs(\n",
    "    folder=os.path.join(ACS_DIR, \"ACS_race\"), col_map=race_cols, topic=\"race\"\n",
    ")\n",
    "\n",
    "print(rent.columns)\n",
    "print(pop.columns)\n",
    "print(poverty.columns)\n",
    "print(race.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- IMPORT EDUCATION TABLE (special case) ---\n",
    "# Define education columns mapping for aggregation\n",
    "education_groups = {\n",
    "    \"education_no_diploma\": [\n",
    "        \"B15003_002E\",\n",
    "        \"B15003_003E\",\n",
    "        \"B15003_004E\",\n",
    "        \"B15003_005E\",\n",
    "        \"B15003_006E\",\n",
    "        \"B15003_007E\",\n",
    "        \"B15003_008E\",\n",
    "        \"B15003_009E\",\n",
    "        \"B15003_010E\",\n",
    "        \"B15003_011E\",\n",
    "        \"B15003_012E\",\n",
    "        \"B15003_013E\",\n",
    "        \"B15003_014E\",\n",
    "        \"B15003_015E\",\n",
    "        \"B15003_016E\",\n",
    "    ],\n",
    "    \"education_high_school\": [\n",
    "        \"B15003_017E\",\n",
    "        \"B15003_018E\",\n",
    "        \"B15003_019E\",\n",
    "        \"B15003_020E\",\n",
    "    ],\n",
    "    \"education_associates\": [\"B15003_021E\"],\n",
    "    \"education_bachelors\": [\"B15003_022E\"],\n",
    "    \"education_masters\": [\"B15003_023E\"],\n",
    "    \"education_professional\": [\"B15003_024E\"],\n",
    "    \"education_doctorate\": [\"B15003_025E\"],\n",
    "}\n",
    "\n",
    "# Flatten the mapping for column import\n",
    "education_cols = {col: col for group in education_groups.values() for col in group}\n",
    "\n",
    "# Load and aggregate the education data\n",
    "education_raw = load_clean_acs(\n",
    "    folder=os.path.join(ACS_DIR, \"ACS_education\"),\n",
    "    col_map=education_cols,\n",
    "    topic=\"education\",\n",
    ")\n",
    "\n",
    "# Aggregate the columns into categories\n",
    "education = education_raw.copy()\n",
    "for new_col, old_cols in education_groups.items():\n",
    "    education[new_col] = education[old_cols].sum(axis=1)\n",
    "\n",
    "# Keep only GEOID, year, and new education summary columns\n",
    "education = education[[\"GEOID\", \"year\"] + list(education_groups.keys())]\n",
    "\n",
    "print(education.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a963e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- MERGE DATA ---\n",
    "# Merge on geoid \n",
    "acs_merged = (\n",
    "    rent.merge(pop, on=[\"GEOID\", \"year\"], how=\"inner\")\n",
    "    .merge(poverty, on=[\"GEOID\", \"year\"], how=\"inner\")\n",
    "    .merge(race, on=[\"GEOID\", \"year\"], how=\"inner\")\n",
    "    .merge(education, on=[\"GEOID\", \"year\"], how=\"inner\")\n",
    ")\n",
    "acs_merged = acs_merged[acs_merged[\"GEOID\"] != \"Geography\"]\n",
    "\n",
    "preview_df(acs_merged)\n",
    "print(acs_merged.head())\n",
    "print(acs_merged.dtypes)\n",
    "\n",
    "print(acs_merged[\"GEOID\"].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cbaa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- ADD CENSUS TRACTS GEO DATA ---\n",
    "# Load NYC Census Tracts\n",
    "gdf_tracts = gpd.read_file(TRACTS_PATH)\n",
    "gdf_tracts = gdf_tracts.to_crs(epsg=2263)\n",
    "\n",
    "# Clean ACS GEOIDs to match shapefile format (drop prefix)\n",
    "acs_merged[\"GEOID\"] = acs_merged[\"GEOID\"].str.extract(r\"(\\d{11})\")\n",
    "\n",
    "# Merge ACS data into shapefile (geometry-aware)\n",
    "gdf_acs = gdf_tracts[[\"GEOID\", \"geometry\"]].merge(acs_merged, on=\"GEOID\", how=\"right\")\n",
    "\n",
    "# Drop NA values in essential columns\n",
    "gdf_acs = gdf_acs.dropna(subset=[\"geometry\", \"median_rent\"])\n",
    "\n",
    "# Check for geometry loss or mismatches\n",
    "print(gdf_acs[\"geometry\"].isna().mean())  \n",
    "preview_df(gdf_acs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33040a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- CONVERT GEO ID TO COMPATIBLE FORMAT --- \n",
    "def convert_acs_to_nyc_geoid(geoid):\n",
    "    \"\"\"\n",
    "    Convert ACS GEOID to NYC-style census tract GEOID.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    geoid : str\n",
    "        The GEOID string from ACS data, typically in the format '1500000US<state><county><tract>'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str or float\n",
    "        The NYC-style GEOID as a string, or np.nan if conversion is not possible.\n",
    "    \"\"\"\n",
    "    if not isinstance(geoid, str) or not geoid.startswith(\"1500000US\") or len(geoid) < 19:\n",
    "        return np.nan\n",
    "    cleaned_geoid = geoid[-12:]\n",
    "    county_code = cleaned_geoid[2:5]\n",
    "    tract_part = cleaned_geoid[5:]\n",
    "    borough_prefix = {\n",
    "        \"061\": \"1\",\n",
    "        \"005\": \"2\",\n",
    "        \"047\": \"3\",\n",
    "        \"081\": \"4\",\n",
    "        \"085\": \"5\",\n",
    "    }.get(county_code)\n",
    "    if borough_prefix is None:\n",
    "        return np.nan\n",
    "    return borough_prefix + tract_part.zfill(10)\n",
    "\n",
    "# Apply cleaning directly from 'GEO_ID'\n",
    "acs_merged['GEOID'] = acs_merged['GEOID'].apply(convert_acs_to_nyc_geoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cdf74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- EXPORT\n",
    "# Export merged ACS data as CSV and pickle\n",
    "acs_merged.to_csv(DATA_DIR / \"processed/acs_merged.csv\", index=False)\n",
    "acs_merged.to_pickle(DATA_DIR / \"processed/acs_merged.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ggent-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
